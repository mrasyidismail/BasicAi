{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8c6437",
   "metadata": {},
   "source": [
    "# Age, Gender, Race Prediction using PyTorch and UTKFace Dataset\n",
    "This notebook demonstrates how to build a simple age, gender, and race prediction model using PyTorch and the UTKFace dataset.\n",
    "The UTKFace dataset contains face images with annotations for age, gender, and race.\n",
    "The goal is to create a convolutional neural network (CNN) that can predict these attributes from the images.\n",
    "The dataset can be downloaded from the following link:\n",
    "https://susanqq.github.io/UTKFace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a08bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_DIR = \"./UTKFace\"  # <-- Ubah ke folder dataset Anda\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 150 # Jumlah epoch\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55b551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = [img for img in os.listdir(img_dir) if img.endswith('.jpg')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        # Parse label: [age]_[gender]_[race]_[...] format\n",
    "        age, gender, race = map(int, img_name.split(\"_\")[:3])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor([age], dtype=torch.float32), torch.tensor(gender), torch.tensor(race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae573f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d94427",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UTKFaceDataset(IMG_DIR, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6742a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        self.features = nn.Sequential(*list(base.children())[:-1])\n",
    "        in_features = base.fc.in_features\n",
    "\n",
    "        self.age_head = nn.Linear(in_features, 1)\n",
    "        self.gender_head = nn.Linear(in_features, 2)\n",
    "        self.race_head = nn.Linear(in_features, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        age = self.age_head(x)\n",
    "        gender = self.gender_head(x)\n",
    "        race = self.race_head(x)\n",
    "        return age, gender, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5446939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputResNet().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ab7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_loss_fn = nn.MSELoss()\n",
    "gender_loss_fn = nn.CrossEntropyLoss()\n",
    "race_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7deca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Loss: 452.7658\n",
      "Epoch [2/150], Loss: 73.2009\n",
      "Epoch [3/150], Loss: 50.7078\n",
      "Epoch [4/150], Loss: 38.3509\n",
      "Epoch [5/150], Loss: 28.3772\n",
      "Epoch [6/150], Loss: 21.5576\n",
      "Epoch [7/150], Loss: 17.5735\n",
      "Epoch [8/150], Loss: 14.0118\n",
      "Epoch [9/150], Loss: 11.9285\n",
      "Epoch [10/150], Loss: 10.8906\n",
      "Epoch [11/150], Loss: 10.4092\n",
      "Epoch [12/150], Loss: 10.6913\n",
      "Epoch [13/150], Loss: 9.5668\n",
      "Epoch [14/150], Loss: 8.5065\n",
      "Epoch [15/150], Loss: 7.8767\n",
      "Epoch [16/150], Loss: 7.4071\n",
      "Epoch [17/150], Loss: 7.1895\n",
      "Epoch [18/150], Loss: 7.4876\n",
      "Epoch [19/150], Loss: 6.7455\n",
      "Epoch [20/150], Loss: 6.2042\n",
      "Epoch [21/150], Loss: 5.8174\n",
      "Epoch [22/150], Loss: 5.5818\n",
      "Epoch [23/150], Loss: 5.6936\n",
      "Epoch [24/150], Loss: 5.6207\n",
      "Epoch [25/150], Loss: 5.0096\n",
      "Epoch [26/150], Loss: 4.9786\n",
      "Epoch [27/150], Loss: 4.8941\n",
      "Epoch [28/150], Loss: 4.7088\n",
      "Epoch [29/150], Loss: 4.3307\n",
      "Epoch [30/150], Loss: 4.2713\n",
      "Epoch [31/150], Loss: 4.1801\n",
      "Epoch [32/150], Loss: 3.8151\n",
      "Epoch [33/150], Loss: 3.8038\n",
      "Epoch [34/150], Loss: 3.9816\n",
      "Epoch [35/150], Loss: 3.4623\n",
      "Epoch [36/150], Loss: 3.2843\n",
      "Epoch [37/150], Loss: 3.3138\n",
      "Epoch [38/150], Loss: 3.2854\n",
      "Epoch [39/150], Loss: 3.2984\n",
      "Epoch [40/150], Loss: 3.9232\n",
      "Epoch [41/150], Loss: 4.9271\n",
      "Epoch [42/150], Loss: 2.6781\n",
      "Epoch [43/150], Loss: 2.0471\n",
      "Epoch [44/150], Loss: 2.3963\n",
      "Epoch [45/150], Loss: 2.7285\n",
      "Epoch [46/150], Loss: 2.9246\n",
      "Epoch [47/150], Loss: 2.9242\n",
      "Epoch [48/150], Loss: 2.7901\n",
      "Epoch [49/150], Loss: 2.6402\n",
      "Epoch [50/150], Loss: 2.4638\n",
      "Epoch [51/150], Loss: 2.4384\n",
      "Epoch [52/150], Loss: 2.4929\n",
      "Epoch [53/150], Loss: 2.9320\n",
      "Epoch [54/150], Loss: 2.4098\n",
      "Epoch [55/150], Loss: 2.1897\n",
      "Epoch [56/150], Loss: 2.1111\n",
      "Epoch [57/150], Loss: 2.2282\n",
      "Epoch [58/150], Loss: 2.3482\n",
      "Epoch [59/150], Loss: 2.2688\n",
      "Epoch [60/150], Loss: 2.2053\n",
      "Epoch [61/150], Loss: 2.1822\n",
      "Epoch [62/150], Loss: 2.1342\n",
      "Epoch [63/150], Loss: 2.1281\n",
      "Epoch [64/150], Loss: 2.1227\n",
      "Epoch [65/150], Loss: 2.0419\n",
      "Epoch [66/150], Loss: 1.9675\n",
      "Epoch [67/150], Loss: 2.7908\n",
      "Epoch [68/150], Loss: 1.7182\n",
      "Epoch [69/150], Loss: 1.4857\n",
      "Epoch [70/150], Loss: 1.6026\n",
      "Epoch [71/150], Loss: 1.9224\n",
      "Epoch [72/150], Loss: 1.9922\n",
      "Epoch [73/150], Loss: 1.9063\n",
      "Epoch [74/150], Loss: 1.8493\n",
      "Epoch [75/150], Loss: 1.8097\n",
      "Epoch [76/150], Loss: 1.8045\n",
      "Epoch [77/150], Loss: 1.7133\n",
      "Epoch [78/150], Loss: 1.8935\n",
      "Epoch [79/150], Loss: 1.7995\n",
      "Epoch [80/150], Loss: 1.6715\n",
      "Epoch [81/150], Loss: 1.6740\n",
      "Epoch [82/150], Loss: 1.6710\n",
      "Epoch [83/150], Loss: 3.1473\n",
      "Epoch [84/150], Loss: 1.8238\n",
      "Epoch [85/150], Loss: 1.2217\n",
      "Epoch [86/150], Loss: 2.6106\n",
      "Epoch [87/150], Loss: 2.9214\n",
      "Epoch [88/150], Loss: 1.4092\n",
      "Epoch [89/150], Loss: 1.1319\n",
      "Epoch [90/150], Loss: 1.1456\n",
      "Epoch [91/150], Loss: 1.2271\n",
      "Epoch [92/150], Loss: 1.4026\n",
      "Epoch [93/150], Loss: 1.5995\n",
      "Epoch [94/150], Loss: 1.8992\n",
      "Epoch [95/150], Loss: 3.3641\n",
      "Epoch [96/150], Loss: 1.5717\n",
      "Epoch [97/150], Loss: 1.1415\n",
      "Epoch [98/150], Loss: 1.1157\n",
      "Epoch [99/150], Loss: 1.2107\n",
      "Epoch [100/150], Loss: 1.3686\n",
      "Epoch [101/150], Loss: 1.5324\n",
      "Epoch [102/150], Loss: 1.5799\n",
      "Epoch [103/150], Loss: 1.5965\n",
      "Epoch [104/150], Loss: 1.5387\n",
      "Epoch [105/150], Loss: 1.5814\n",
      "Epoch [106/150], Loss: 1.4578\n",
      "Epoch [107/150], Loss: 1.3521\n",
      "Epoch [108/150], Loss: 1.5730\n",
      "Epoch [109/150], Loss: 1.4300\n",
      "Epoch [110/150], Loss: 1.4318\n",
      "Epoch [111/150], Loss: 1.3881\n",
      "Epoch [112/150], Loss: 2.6080\n",
      "Epoch [113/150], Loss: 1.5819\n",
      "Epoch [114/150], Loss: 1.0695\n",
      "Epoch [115/150], Loss: 0.9827\n",
      "Epoch [116/150], Loss: 1.0519\n",
      "Epoch [117/150], Loss: 1.1690\n",
      "Epoch [118/150], Loss: 1.2992\n",
      "Epoch [119/150], Loss: 2.4092\n",
      "Epoch [120/150], Loss: 1.2737\n",
      "Epoch [121/150], Loss: 1.0220\n",
      "Epoch [122/150], Loss: 1.0407\n",
      "Epoch [123/150], Loss: 1.1405\n",
      "Epoch [124/150], Loss: 1.3391\n",
      "Epoch [125/150], Loss: 2.1162\n",
      "Epoch [126/150], Loss: 1.3429\n",
      "Epoch [127/150], Loss: 1.0474\n",
      "Epoch [128/150], Loss: 1.0777\n",
      "Epoch [129/150], Loss: 1.9392\n",
      "Epoch [130/150], Loss: 1.3181\n",
      "Epoch [131/150], Loss: 1.0041\n",
      "Epoch [132/150], Loss: 1.0462\n",
      "Epoch [133/150], Loss: 1.1411\n",
      "Epoch [134/150], Loss: 1.4366\n",
      "Epoch [135/150], Loss: 1.2552\n",
      "Epoch [136/150], Loss: 1.2857\n",
      "Epoch [137/150], Loss: 1.2232\n",
      "Epoch [138/150], Loss: 1.3817\n",
      "Epoch [139/150], Loss: 1.5165\n",
      "Epoch [140/150], Loss: 1.1467\n",
      "Epoch [141/150], Loss: 1.0510\n",
      "Epoch [142/150], Loss: 1.0700\n",
      "Epoch [143/150], Loss: 1.1123\n",
      "Epoch [144/150], Loss: 1.2898\n",
      "Epoch [145/150], Loss: 1.2350\n",
      "Epoch [146/150], Loss: 1.8093\n",
      "Epoch [147/150], Loss: 1.9115\n",
      "Epoch [148/150], Loss: 1.0127\n",
      "Epoch [149/150], Loss: 0.9085\n",
      "Epoch [150/150], Loss: 0.9095\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, ages, genders, races in train_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        ages = ages.to(DEVICE)\n",
    "        genders = genders.to(DEVICE)\n",
    "        races = races.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_age, pred_gender, pred_race = model(images)\n",
    "\n",
    "        loss_age = age_loss_fn(pred_age, ages)\n",
    "        loss_gender = gender_loss_fn(pred_gender, genders)\n",
    "        loss_race = race_loss_fn(pred_race, races)\n",
    "\n",
    "        loss = loss_age + loss_gender + loss_race\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27cc4c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as multioutput_utkface.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"multioutput_utkface.pth\")\n",
    "print(\"✅ Model saved as multioutput_utkface.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
